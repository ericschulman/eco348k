{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #general library, will come in handy later\n",
    "import random #this library is for choosing random numbers\n",
    "import matplotlib.pyplot as plt #this library is for graphing things\n",
    "import statsmodels.api as sm #this is for linear regression\n",
    "\n",
    "#note this extra library\n",
    "import pandas as pd #another nice library for storing matrices, it rely's on numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fda672fcf10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXN5NJJnvIyhYIkIALqyKiKOJSr1rrUm1LF61eK9Val19X7b211Xpva3u72fbqpWqr1hYR96W0WlEBFUyQfd8JBLJAyL7MzPf3x5yEkGQmgSQkJ7yfj0ceM5k5M/M9HnnnO5/zPd+vsdYiIiIDS1RfN0BERHqewl1EZABSuIuIDEAKdxGRAUjhLiIyACncRUQGIIW7iMgApHAXERmAFO4iIgNQdF99cEZGhs3Nze2rjxcRcaXCwsIya21mZ9v1Wbjn5uZSUFDQVx8vIuJKxphdXdlOZRkRkQFI4S4iMgAp3EVEBiCFu4jIAKRwFxEZgBTuIiIDkMJdRGQAcm24N/qDzC/Yg5YJFBFpz7XhvnRrGd9bsJp1+yr7uikiIv2Oa8O9wR8EoL4p0MctERHpf1wb7oFgqBzTFFBZRkSkLdeGuz8YPOpWRESOcG24B50TqX713EVE2nFtuDeHemNAPXcRkbZcG+7NNXf13EVE2nNvuDeXZVRzFxFpx73h7vTcG/0KdxGRtlwb7s3lGH9QZRkRkbZcG+5HRsuo5y4i0pZrw92vi5hERMJybbgfuUJVPXcRkbZcG+6quYuIhOfacG8eCqmeu4hIe+4Nd2d8u8JdRKQ914a7X1eoioiE5dpwD2q0jIhIWK4N95aeu6YfEBFpx7XhrqGQIiLhDYBwV1lGRKQt14e7ph8QEWnPteHeMv2ALmISEWnHteHeMlpGU/6KiLTj2nA/MlpGPXcRkba6HO7GGI8x5hNjzOsdPBdrjHnOGLPVGLPMGJPbk43siEbLiIiEdyw997uBDWGeuwU4ZK3NA34NPNzdhnVG4S4iEl6Xwt0YMxz4NPB4mE2uBp5y7i8ALjbGmO43LzxNPyAiEl5Xe+6/Ab4HhOsmDwP2AFhr/cBhIL3tRsaYOcaYAmNMQWlp6XE094iWicNUcxcRaafTcDfGXAmUWGsLI23WwWPtUtdaO9daO9VaOzUzM/MYmtlec4dd49xFRNrrSs99BnCVMWYnMA+4yBjzlzbbFAE5AMaYaCAFONiD7WxHU/6KiITXabhba++z1g631uYCs4F3rLVfabPZq8BXnfvXO9v0ar2kZSUm1dxFRNqJPt4XGmMeBAqsta8CTwDPGGO2Euqxz+6h9oUVbF6JSbNCioi0c0zhbq19F3jXuX9/q8frgc/1ZMM60zL9gF89dxGRtlx7hWpA87mLiITl2nBvrrVryl8RkfZcG+7NNXcNhRQRac+14e7XYh0iImG5Ntxb5pZRzV1EpB3Xh7u1R+6LiEiI68MddJWqiEhbrg331kMgFe4iIkdzbbi3znNNQSAicjQXh3uQKGcuyhN9UvVXb23m9+9sOaGfKSJyLI57bpm+5g9a4rweahoDFO48xGXjB9PL64Pw8MKNAPxp6Q5S4rzccWFer3+miMjxcG3PPRi0+LweAG5/dgWLt5RF3L6+KdDtz3z03W08+u426puCHKhsYG9FXbffU0SkN7g23P1BS2z0kebXRQjvwl0HOeWHC1m4tvi4P+9gTWPL/WinHlS469Bxv5+ISG9ybbgHghZfjKfl93DTx9c2+rnrbyuByGF87f8u5a/Ldod9fmtJNQAz8tK5/zOnER/j4ZPdFcfTdBGRXufecLeW1nle29hxz/03b29pKZ/UhNmmusHPJ7srWLwl/LquW0qqAHj4uonceE4uE4alsKpI4S4i/ZMrwz0YDAV761OZHZVlSqsaeGLJDmaflcMpg5Moqazv8P2KnfDfVlp91ONFh2qpqA2VY7YcqCY+xsPQlDgAxmYnsbWkOuw3BhGRvuTKcG+eNOyaKcP47ezJANR10CvfVV5DIGi5bPxgspN9lFQ1dPh++w6HQn9nWe1Rs0ze8MRyHnxtPRAqy+RlJRLl1NvHZCZQVe+ntLrj9xQR6UuuDPfm6X69niiumDAE6Hg0zH6npz44xUd2ciwHOum5NwaCFB2qa3m/neU1fLKngqZAkJV7Kjh9aErLa8ZkJQKwraSmh/ZKRKTnuDLcm3vu0VEGryeK6CjDyj2Hyb33DT7aXt6y3X6nRz442Ud2so/SqoYOJxlr7rkD/PTvG9i4v5KiQ7VYCzvKaliypYzqBj8XjM1o2W5MphPubUo5IiL9gSsvYgo40w14nBJJXIyHJVtDJ0MXFBYxNjuJO/+2gthoD7HRUaTEeclK9hG0UF7dQFay76j3K66oIyEmdEHUP9YdoL4pyI3njGx5/rH3thFl4JwxR8J9SIqP+BiPwl1E+iVXhnvzpGEt4e71OCNnghyqaeSlT/aydGuoBz8yPR5jDFlJsQAcqOwg3A/Xk5edRCAYZO3eSpoCQXaW17Y8v2zHQaaMSCUlztvymDGGMZmJbCtVWUZE+h9XlmUCtn3PvbrBD8DB2kZe/mRvy7bZTpA333ZUd993uI6hKT5e++Z5XD5+MAcq69ldXkNS7JG/fd+9dFy7143JTGBbiXruItL/uLLnHmhVc4dQz73Zur2VNAaCeKIMgaBlcEu4Oz33qqPD3VrL/sP1zBqbhTGGISlxvLe5lJ3ltYxIj+e/rp1AfIyHsdlJ7doxJjORl1fuo64xQFyrC6pERPqaK3vuzVP8RrXquTdrdIYyXj15KBAaKQMwKD4GgIrapqPeq7rBT21jgMEpofAfkuKjtjHAun2HGZkez+Sc1A6DHY6MmNlept67iPQvrgz35qGQHfXcAcZmJ3LpadkALT13n9dDnNfDoVZzxECoBg+QlRTarvmPQVl1I6cNSY7YjiMjZlR3F5H+xZXh3jwU0hMm3GeNy+KMkYPISIxhUk5qy+Op8V4q6o7uuZc4ZZrmE65DU4+cbD1jxKCI7RiZHk+UOTLvjIhIf+HqmntzuDdPIJYYG02SL5qrJg0lK8lHwX9+6qjXpcbHtEwn0KzUuWo1y6nJD3amF4gyHPWHoSM+r4ectHgNhxSRfsfV4d5clol3eu55WYm8fMeMsK9LjfO2q7mXOGWZTKcsk5UUizEwbnAyCbGd/+fJz0pk/b7KY98JEZFe5MqyzJGee6j5zSdUk3yRw3hQQsdlmdjoKJKd13o9UYzLTuLCcZldass5YzLYUVZD0aHazjcWETlBXNlzP1JzD/3eXHPvLNxT4tqXZUqqGshKjj1qubzX7jyPqC4unzczP3TV6uItZXxx2oguvUZEpLcNiJ5783J7iZ2UUVLjQ2WZ1tP0llQ2tIyUaeb1RLXU8zuTl5XIkBQf728OPxe8iMiJ5upwj24zzj0x1hv2NQCD4r34g5bqBj9z39/GjrIaSqrqW0bKHA9jDNNHp2tVJhHpV1wZ7s1zyzSXTuK7WHNPjQtdyPT3Nfv57zc38tKKolBZphvhDnDqkCT2V9a3K/mIiPSVTsPdGOMzxiw3xqwyxqwzxjzQwTY3GWNKjTErnZ+v9U5zQ5xsJ9rjDIXsYs09NT7Us//doi0AFB2qo6re324isWM1bnDoYqeN+6u69T4iIj2lKz33BuAia+0kYDJwmTFmegfbPWetnez8PN6jrWyjo1khoSs191DPfc/B0IIc64tDQxgzu9tzHxyanmBjsYZEikj/0Gm425Dmq3S8zk+fLhzackLVHB3uSb7Oa+4QqtXnZyW2XFna3bJMZlIsyb5ofvzaeuY8XdCt9xIR6QldGgppjPEAhUAe8Adr7bIONrvOGDMT2Az8P2vtnohvumkTzJp1bK11TKlpZN6BKvLeS4HYaM6qa2JecSWnLEqGuPABPzIQZN6uQ6QnhsK83Fn/dML7qdCNWR0N8OfdFTT6Q0v91c8dhC/alaczRE4altDay02BINEegz8QGmxRXt3IyPT4lvUbLKHJCr2ero2ga8sftJRXN2CMITXOS8wJyoYuhbu1NgBMNsakAi8ZY8Zba9e22uQ14G/W2gZjzG3AU8BFbd/HGDMHmAMwMbZ7vWXnDYFQjz0nLb7lQqRwvJ4oRqYnkJYQQ3GrpfVijvOgtZaXFVowe8/BWg7VNDIkpXt1fBHpHUELZdUN7Kuo63DtZU+UYUNxJUNT4/B5Pew/XE9to58kn5dRGQnUNwUoPlxPki+aWK+HyromEmOjMQZS4rz4nAkKS6oaqG300+gPHnlzYxicHEtOWnxL5aG3mNZjvrv0AmN+BNRYa/8nzPMe4KC1NqWj55tNnTrVFhQcXwnjzTXFfOPZFfzjnpmMG9zxdLydefTdbTy8cCPRUYbND13eMn1wd132m/dJ9nmZf9s5PfJ+ItIzahv9zFu+hz8u3k7x4XpOHZLMzefmMiTVR2Wdv2XAxaScVH748lpechb9yctK5FOnZTP/4z2UO7PKDknxsb+yHmshKTaaKmexIAhNSbKlpJphqXGcPSqN3IwELj41ixhPFE99uJO/fLSbL589gv+6dsJx7YcxptBaO7Wz7TrtuRtjMoEma22FMSYOuAR4uM02Q6y1xc6vVwEbjqPNXdY85W938jgjMca5je2xYAeYOTaTP3+wk6ZAEK9HpRmRE626wc9fPtpFXWOAOy7MIyY6innLd/Pwwo0cqm1iWm4a//3ZCcwam3nUlemt/foLk/nWp8ZSUdvE6UOTiYoy3Dwjl+cLihic7OPKSUOoawxwoLKBvKxEdpXXYIzh1ZX7+Of6/Xz/slO49fxRRLfJgIeumcDl44eQ56wF0Zu6UpYZAjzl9MijgPnW2teNMQ8CBdbaV4G7jDFXAX7gIHBTbzUYQl+rgLAHpisynLp782yQPWX8sBQa/UE2H6ji9KERv7yIyDGw1nb4b760qoHvLlhFXWOAfz9vFD99c0PLGshLtpYxJjOB+QVFTB+dxncuHcfU3LQufV5OWjw5rTbNSvJxx4V5Lb/HRntaRuCNdtZ2uPuSfO6+JD/i+87Iy+jS53dXp+FurV0NTOng8ftb3b8PuK9nmxaxTUB3e+5OuHdzpExbE4aFAn3t3sMKd5EeUFnfxA9eXMOijSXkZiRw2wVjGJOZyDMf7WLxllKKDtUR44ki2mP4+jOFZCTGMm/OdMqqG/jegtUU7jrEN2aN4duXjuvytCIDgSsnDjtSlulGzz0p9Bc3M6lnT3yOTIsnKTaa77+whrfWl/DTz07o9jh6kYGmpsGP1xPFHxdvZ+WeCq6dMowrJgxhdVEF1fV+Xl9TTKM/yNAUH6+s2sfeQ3V8bupwlu04yJ1/+wSAmOgoPnVqNl+cNoKLT80i2edlR1kNE4entAyLHj80hQOV9Zw9Or0vd7dPuDPcnZPP3Qn39IRY4mM8jMqI76FWhURFGZJ8oRMsb284QNETtSy8Z2bE1xTsPMi8j/dw+6wxLUv3iQxEdY0BHnx9Hc99vIfE2Ggq6/1kJcXy1voDjEyPZ5dTTvF5o0iJ83KgsoGx2Yn85WtnM310OoGgZdHGEqoamjh3TAbZba4uH5oad9TvuRkJ5GYknLD960/cGe5Oz707I4lioqP4xz0ze6VX/d3LxrFkSzl5WYk8vHAjxYfrGJIS1+G2K/dU8OXHl9HgD/LmmmLe++6F6ulLp3aX15KeGNOlBWV608GaRhZvKeXy8UMIWsv7m0s5XNfECyuKiI32UF7TwG0XjCHO6+HPH+xkb0UdO8pq+PyZOWwtreYLU3O4ZsowHn13G2v2HuaG6SMZk5XI6UOSyUr2Ud8UIDY6qqXW7okyXOKsjyyRuTLcm0dvdneUS05az/bam107ZTjXThnOJ7sPAbBydwVDJnQc7nPf30ZCbDSP3TCJm//0Me9vLuW6M4f3SrvE3f614QAj0uJ5c81+HnlnC2Ozk5h7w5kMHxTX4YnGYNDykzfW4w9YfvSZ09qN3IgkNBKknsykWJbvPMjWA9Us2VrGQ9eMJyctnjVFh3liyXbe2VhCZb2fJ4bvoLy6kb0Voak9RmUkEOf1UN8U4Jt/DZVRhqXGkZEUyx++dAZXTBhy1OeFOwnp8x7/xYUnO1eGe08MhTwRThuaTIwniucK9tAUtNQ3BvjTBzt5/c7z+HBbOc8X7uGt9Qe48ZxcLsjPJCMxhsVbFO7S3rzlu7n3xTUtv198ShaLt5Rx/s8XccWEwfx29hQa/UFW7D7EmMxEBsXHcP8ra3m+sAgIXbTzyBenEB1lWFBYxPOFRcR4ojg/P4PDdU1MzkllfXElb284wMWnZLOgsIjiw3WMSItvGXni9Riu/d+lzMjL4NVV+0iJ8zJrXBanDU3mmQ93kZsRzwNXnU5qvJcpIwbhiTLUNwV4YUURGYmxzBqXSWy0wvpEcWm4h267U3M/EWKjPWQkxvDuplLe3VTK0BQf+w7XM+/j3Tz42noanCvXPj81h6gow/n5mby/uRR/IHhMvSwZ2JZuLeM/X17L+fkZjM1OYsqIVK6cOJQtB6p48ZO9PPruNj7a/i+q6ptoClhS4rykJcSwo6yGOy/KIyXOy0NvbODy3y4maC3bS2sYl53EodpGlmwtwxNlWuZrGhTv5bf/2sL4YcmMSIuncNchfnH9RPKzk4iP8fC9Bat5bdU+vnpOLt+6dCzJzonL2y4Y02HbfV4PXz575An7byVHuDTcu19zP1E+e8Zwfr9oK54owz5nyoMHXltPYmw0r985nUO1TS1X2f7b6dm89MlePv3IEhbcfk6nE6FJ/3S4tomF64r5zKShxMcc/z+xokO1/PDltSzeUsbozAT+8OUzWsIUID87ie9fdgoThqXw7qYSBiXEMCUnlZ+8voFGf5C/3no2544JjakeFB/Dyyv34oky3DZzDNefOZzGQJDKuibSEmJ4bfU+ig/XM+f80dQ2BUj2eQkGLRXO881e+sa5NAaC6oG7wDFPP9BTujP9wDMf7uSHr6yj4D8vaRmv3l8Fgpb6pgDfmr+Sf64/wKD4GA7WNPLVc0bywNXjj9rWWsuCwiK+u2A1v509masnD+ujVsvxCgYtN//5Y97bXMrI9Hh+cf0kpo1Ko7y6gZ+8vp4Vuyt4+LqJnDMm8tC8t9Yf4NvzV2ItfGn6CG6ZMarL6w7UNQbwRJkTNkGVnFhdnX7AlUe/+Stkfy/LQOjsfkJsNPd/5nTm3jCVC8dlAXD1lPbBbYzhujOGk54Qw782lJzopko3NPqDNPqDfHfBat7bXMrNM3KxFr4w90NeKCzirnmf8Oba/fgDQeY8XcCCwiKeXbaLqvomDtY0HjWB1dvrDzDnmQJGpifw+l3ncd/lpx7TgjJxMR4Fu7i1LBO67e1Z1XrSsNQ4hqXGkZ0cS0Zi6OtzR6KiDLPGZfH2hgOqvbtAoz/IfS+uYeHaYqaNSmPRplLuuSSfuy/O5zuXjuPGJ5fz7edXAfDz6yYyIz+DW/78Md9xHvvj+9vZWV5LdJThwavHc1buIO55biXjh6Yw/+vntKwPLHKsXBruTs3dhbk3cXgqE4d3HOzNLj41ixdWFLFidwXTRnVtHgw58Q7XNXHbM4V8uL2c1HgvizaV8vULRnPPJWMBSIiN5vEbp/LX5buZPjqdM0cOAuC1O8/jo+3l7Cqv5f5X1nLN5KGU1zTyHy+vISk2Gp/Xw9wbz1SwS7e4MtytS0bLHK/z8zOIjjK8s7GEgzUN/PKfm3niq2cxIr13xuXLsbPW8u35KynYdZBffX4SZ4wYxJtri7n1/NFHbTcoIeaoyaYgtK7A+fmZnJ8PV00eSrLPS31TgN+8vYVd5TXcPmtM2IveRLrKleHulnHuxyvJ5+Xs0WnML9jD44u34w9aXvpkb6ezzcmJsaOshv96YwNvbyjhh1eexmfPCF2X8I1ZeZ28sr3m0S8+r4d7Lz+lR9spJzcXFjbcM869Oy4cl8XBmkYmDk9hwrAU/rFuf1836aRWXt3AW+sPsHbvYeY8XcCyHeXceVEeN5+b29dNE+mQq3vuAzjbmT1tBNbC7Gk5PPfxHh56YwPbS6tb5o2W3vXEkh28snIvOWnxjEyL55WV+1ourQd46t+nccHYzD5soUhkrgx32wNT/vZ3ibHR3DozVL/9zKSh/PKfm/nZ3zcy98ZOh7dKN63bd5ifvrmBEWnxrNt7mIVr95OWEMPjN06lwR8kLiZKwS79nivD/WQoy7SWnezjzovz+PnCTSzaVNIyVl56XlMgyPcWrCY1PoYXv3EuqfExNAWCGNCwVHEVl4b7wD6h2pGvnTeaBQVFPPDqOvJuSTxqRsvtpdVkJftI7OPpX92orjHAyyv3svdQHcMGxbFseznr9lXy2FfObFlCTWvhihu5Mg16Yg1Vt4mJjuLBq8dz45PLmPmLRfzmC5OpbvCTm57AV55YhjcqiidvOovz8k/M+owDQTBoueGJZRTsOoQxoSG2Xo/h6xeM5rLxg/u6eSLd4spwt9aeVL32ZuflZ7DoO7O4468ruHveSiAURgkx0STEepi7eHu/C3drLVUN/qMmvOoJ9U2BiHN9byiuJCsplihj+Ovy3UwYlkJGYixxMR6GpvqIjori2WW7KNh1iP++dgKfnzqc/ZX1JMREM6jVRFkibuXKcA9ae9LU29samZ7Aw9dN5NanCsjLTuL9zaXcPGMEvugofrdoK/sq6totNRaObRl11Hv/LX+2cCN/XrqT1+48j7HZSWG3K69u4O0NB7h68jCq6v1hV6MKBi0/W7iRPy3dwTcv7Hil+d3ltVz9h6XkDIqjqt5PSVUDcV4PAWvBQmx0FIm+aEqrGpg5NpMvTsvBGMPwQbpITAYOl4b7yXMytSOnD03hg/suxh8I8uqqfVx6+mAOVjfyyDtbWVBYxF0Xd36x08b9ldz2TCFl1Y18//JTuGF69+fc3ltRx9q9h/nUqdlU1DWx+UAV//fedgB+9Mo6nv3a2R2unrXlQBXXPfoBlfV+/rp8D6v2VHDzjFwWbSwhyhhyMxL4j0+fypjMRN5YU8zc97czMj2e3/5rM+fmpTN+aApf/ONHnDokmUAwyIrdFRhge1kNyT4vf7rpLL67YDWD4r1Mykml0R9k7d7DTBiewu+/NOWkKu/JycOVU/7+9O8b+PPSnWx66PIebpW7femPH7HnUC3vfefCiEsQvre5lDueXUFCrIfBKXFsL6lm6X0Xdat00ugPctXvl7BxfxXTRqWxuqiC3PQEKmqbuHXmaH7y+no+PXEIj8yegqdN277xbCGLN5dx/tgM3lyzn+gogz9oyU6O5cyRg1iypYyctHgeumY8d837hISYaObfdg5XPrKEQNDyb6cP5smlOwBIiPGQnezjphm55AyKZ/igOPKzk6iobcTn9bSUcoLNM4uejPU9cbWuTvnryp67Pcl77uF8fmoO9zy3kiVby5gZZhx2fVOAbz67gpy0eP5001mUVTdw5e+WcM+8lXzzojzysxKJMuaYF15+fMl2Nu6vIik2muU7DgKwcX8V911+CrecN4oGf4CfL9zEqPQEfN4oRqQncOWEIbyyai9vrtnPnRflMWfmaCYOT+W8vAx+/dZm7r4kn4nDU/nHuv18/ZlCrv3fD0iMjeYX108i2eflN7Mn87nHPuTJpTu47PTB3H1JPoOTfR3WzJtHvjRTqMtA58qe+0Ovr+dvy3ez7sHLerhV7lbfFODiX76HMfDGXeeTEte+J75w7X5u+0shf7nl7JaTrw+8to7nC4oIBC0+bxT5WUk89/XpXS5XNAWCnPfwO4zNTuLrM8fw6qq95GclMXfxdt7+1gWkxHmx1vLlx5fxwbbyltfNyEtn6dZyJuWk8vTN00iJD//NYdWeCnaU1XBefsZRC7RsLalm0/4qZuSltwtwkYFoQC/WcbLX3MPxeT387ktT2FdRx6PvbutwmzfWFJOWEMP00UemEv7RZ07nne9cQFZyLIGgZfnOgyzdeiSE399cyuur93X4fh9sLeNrTxVwoLKBm87N5bz8DH5+/SRunTma5T+4uOUPjDGGn18/kdtnjWHpvRcxfXQaS7eWc8mp2bx4+7kRgx1gUk4q10wZ1m7lrbysRD49cYiCXaQNl4a7HdDzynTHGSMG8anTsplfsOeo1X0A3lhdzN/XFHP5+MHtrrbMSvLxj3tmsuwHlzA42cePXl1LWXUDgaDl3hdW863nVh01twqERtv85I0NfLS9nGm5acxqc+Vs257/8EHxfP+yUxiWGscvrp/ETefm8ovrJ7arwYtI97ky3K21qplGcMP0XA7WNPLmmmKstSxcW8z//GMTd/5tBZNzUvl+mKllfV4PcTEefjN7MkWH6pj60Nt8+pHF7DtcT2MgyG/f3tyybUVtI/ML9rChuJL7P3Ma828755hCOictnh9fdbrGlIv0EleeUA2cxOPcu2JGXjqjMxN4+sNdbC+t4feLtgKhRUD+74YziY+JfNinj07n+dvO4Y3Vxfxx8XZS4rxcNWkozy7bxZyZoxmTmcicpwtZvvMgSbHRXKOFvEX6HVeGu2rukRlj+MrZI3nw9fWs3FPB7LNy+H+fGktWUmyXT5I2Lwc4Iy8DC0wYlsJLn+zl1qcLGT4ojuU7D3LPJflcOXHoMY+sEZHe58p/lSfr9APH4rozhzP3/e1cdGoWD109/rjLWK2HVP7sugk8uWQHeyvquOz0wdx1Ub7KYyL9lCvDPRhUz70zKXFelt57UY+erLxy4lCunDi0x95PRHqPK0+oBtVz7xKNQhE5ebk03E+u6X5FRI5Vp+FujPEZY5YbY1YZY9YZYx7oYJtYY8xzxpitxphlxpjc3mhss9BQyN78BBERd+tKRDYAF1lrJwGTgcuMMdPbbHMLcMhamwf8Gni4Z5t5tJN5yl8Rka7oNNxtSLXzq9f5aTshzdXAU879BcDFphfrJhoKKSISWZeKG8YYjzFmJVACvGWtXdZmk2HAHgBrrR84DKR38D5zjDEFxpiC0tLS4260ph8QEYmsS+FurQ1YaycDw4FpxpjxbTbpKGrbTTdprZ1rrZ1qrZ2amdnxlLRda4967iIikRzTaUlrbQXwLtB2rt0iIAfAGBMNpACR8uq3AAAJ2klEQVQHe6B9HdJQSBGRyLoyWibTGJPq3I8DLgE2ttnsVeCrzv3rgXdsL04UrxOqIiKRdeUK1SHAU8YYD6E/BvOtta8bYx4ECqy1rwJPAM8YY7YS6rHP7rUWo3HuIiKd6TTcrbWrgSkdPH5/q/v1wOd6tmkR26SyjIhIBK68FEhDIUVEInNpuKvnLiISiUvDXTV3EZFIXBnuqrmLiETmynDXUEgRkchcGe6BoMJdRCQSV4Z7qObe160QEem/XBnu1lqtMiQiEoErw13j3EVEInNpuGvKXxGRSFwa7uq5i4hE4spw1zh3EZHIXBnuGucuIhKZO8M9qOkHREQicWe4qywjIhKRK8Nda6iKiETmynAPWkuUK1suInJiuDIiQ+Pc1XMXEQnHleGusoyISGSuDHedUBURicyl4a6eu4hIJC4Nd80tIyISiSvDXTV3EZHIXBnuqrmLiETm4nBXuouIhOPKcA9obhkRkYhcGe6a8ldEJDJXhntQa6iKiETk0nDXaBkRkUhcGu4a5y4iEokrw13j3EVEInNluGucu4hIZC4Od6W7iEg4nYa7MSbHGLPIGLPBGLPOGHN3B9vMMsYcNsasdH7u753mhgStxrmLiEQS3YVt/MC3rbUrjDFJQKEx5i1r7fo22y221l7Z801sT+PcRUQi67Tnbq0tttaucO5XARuAYb3dsEg0FFJEJLJjqrkbY3KBKcCyDp4+xxizyhjzd2PM6T3QtrB0QlVEJLKulGUAMMYkAi8A91hrK9s8vQIYaa2tNsZcAbwM5HfwHnOAOQAjRow4rgZba7GquYuIRNSlnrsxxkso2J+11r7Y9nlrbaW1ttq5/ybgNcZkdLDdXGvtVGvt1MzMzONqsLVOwxXuIiJhdWW0jAGeADZYa38VZpvBznYYY6Y571vekw1tFnTSXWUZEZHwulKWmQHcAKwxxqx0HvsBMALAWvsYcD1wuzHGD9QBs61t7mP3rGBzz13pLiISVqfhbq1dAkRMUmvt74Hf91SjImnuuasqIyISnuuuUFXNXUSkc64Ld9XcRUQ65+JwV7qLiITjvnAPhm41zl1EJDz3hbvKMiIinXJtuGsNVRGR8FwY7qFblWVERMJzXbhblWVERDrlunAPapy7iEinXBju6rmLiHTGteGumruISHiuC3dNPyAi0jnXhbvKMiIinXNhuIdu1XMXEQnPheGuKX9FRDrjunC3mjhMRKRTrgt3lWVERDrnwnDXCVURkc64L9w15a+ISKfcF+7quYuIdMp14a6LmEREOue6cG/pubuu5SIiJ47rIlJzy4iIdM614a6yjIhIeC4M99CtTqiKiITnvnB30t2jnruISFjuC3etoSoi0inXhbvWUBUR6Zzrwr2l5q50FxEJy4Xhrp67iEhnXBvuqrmLiITnunDX9AMiIp1zXbirLCMi0rlOw90Yk2OMWWSM2WCMWWeMubuDbYwx5hFjzFZjzGpjzBm901wt1iEi0hXRXdjGD3zbWrvCGJMEFBpj3rLWrm+1zeVAvvNzNvCoc9vjtIaqiEjnOu25W2uLrbUrnPtVwAZgWJvNrgaetiEfAanGmCE93lq0hqqISFccU83dGJMLTAGWtXlqGLCn1e9FtP8D0CNUlhER6VyXw90Ykwi8ANxjra1s+3QHL7EdvMccY0yBMaagtLT02FrqyE728ekJQ0jydaWiJCJycupSQhpjvISC/Vlr7YsdbFIE5LT6fTiwr+1G1tq5wFyAqVOntgv/rjhz5CDOHDnoeF4qInLS6MpoGQM8AWyw1v4qzGavAjc6o2amA4ettcU92E4RETkGXem5zwBuANYYY1Y6j/0AGAFgrX0MeBO4AtgK1AI393xTRUSkqzoNd2vtEjquqbfexgJ39FSjRESke1x3haqIiHRO4S4iMgAp3EVEBiCFu4jIAKRwFxEZgEzzXC0n/IONKQV2HefLM4CyHmxOX9K+9E/al/5J+wIjrbWZnW3UZ+HeHcaYAmvt1L5uR0/QvvRP2pf+SfvSdSrLiIgMQAp3EZEByK3hPrevG9CDtC/9k/alf9K+dJEra+4iIhKZW3vuIiISgevC3RhzmTFmk7MY97193Z5jZYzZaYxZY4xZaYwpcB5LM8a8ZYzZ4tz2ywnrjTFPGmNKjDFrWz3WYdtP5KLpxyPMvvzYGLPXOTYrjTFXtHruPmdfNhlj/q1vWt1euAXs3XhcIuyLG4+Lzxiz3BizytmXB5zHRxljljnH5TljTIzzeKzz+1bn+dxuN8Ja65ofwANsA0YDMcAq4LS+btcx7sNOIKPNYz8H7nXu3ws83NftDNP2mcAZwNrO2k5oCui/E5pRdDqwrK/b34V9+THwnQ62Pc35fy0WGOX8P+jp631w2jYEOMO5nwRsdtrruuMSYV/ceFwMkOjc9xJamnQ6MB+Y7Tz+GHC7c/8bwGPO/dnAc91tg9t67tOArdba7dbaRmAeocW53e5q4Cnn/lPANX3YlrCste8DB9s8HK7tJ2zR9OMRZl/CuRqYZ61tsNbuILRuwbRea9wxsOEXsHfdcYmwL+H05+NirbXVzq9e58cCFwELnMfbHpfm47UAuNhZKOm4uS3cT9hC3L3IAv80xhQaY+Y4j2VbZ+Uq5zarz1p37MK13a3H6ptOueLJVuUxV+xLmwXsXX1c2uwLuPC4GGM8zgJHJcBbhL5ZVFhr/c4mrdvbsi/O84eB9O58vtvCvUsLcfdzM6y1ZwCXA3cYY2b2dYN6iRuP1aPAGGAyUAz80nm83+9LJwvYH7VpB4/1931x5XGx1gastZMJrSk9DTi1o82c2x7fF7eFe5cW4u7PrLX7nNsS4CVCB/1A81dj57ak71p4zMK13XXHylp7wPkHGQT+yJGv+P16X0zHC9i78rh0tC9uPS7NrLUVwLuEau6pxpjmFfBat7dlX5znU+h62bBDbgv3j4F854xzDKETD6/2cZu6zBiTYIxJar4PXAqsJbQPX3U2+yrwSt+08LiEa7vrFk1vU3u+ltCxgdC+zHZGNIwC8oHlJ7p9HXHqsh0tYO+64xJuX1x6XDKNManO/TjgEkLnEBYB1zubtT0uzcfreuAd65xdPW59fVb5OM5CX0HoLPo24D/6uj3H2PbRhM7urwLWNbefUG3tX8AW5zatr9sapv1/I/S1uIlQT+OWcG0n9DXzD85xWgNM7ev2d2FfnnHautr5xzak1fb/4ezLJuDyvm5/q3adR+jr+2pgpfNzhRuPS4R9ceNxmQh84rR5LXC/8/hoQn+AtgLPA7HO4z7n963O86O72wZdoSoiMgC5rSwjIiJdoHAXERmAFO4iIgOQwl1EZABSuIuIDEAKdxGRAUjhLiIyACncRUQGoP8PZVdF653s6TkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#homework question #2\n",
    "\n",
    "dicerolls = [] #initialize rolls\n",
    "means = []  #also calculate means\n",
    "\n",
    "for i in range(300):\n",
    "    dicerolls.append(random.randint(1,6)) #save rolls into  a list\n",
    "    means.append( 1.0*sum(dicerolls)/len(dicerolls) ) #compute mean for each index\n",
    "\n",
    "#graph dice rolls\n",
    "plt.plot(means)\n",
    "plt.axhline(3.5,color='r') #This is assymptotic expected value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         lwage  educ  exper  fatheduc  motheduc  black  smsa  south  nearc4  \\\n",
      "0     6.306275     7     16       NaN       NaN      1     1      0       0   \n",
      "1     6.175867    12      9       8.0       8.0      0     1      0       0   \n",
      "2     6.580639    12     16      14.0      12.0      0     1      0       0   \n",
      "3     5.521461    11     10      11.0      12.0      0     1      0       1   \n",
      "4     6.591674    12     16       8.0       7.0      0     1      0       1   \n",
      "5     6.214608    12      8       9.0      12.0      0     1      0       1   \n",
      "6     6.336826    18      9      14.0      14.0      0     1      0       1   \n",
      "7     6.410175    14      9      14.0      14.0      0     1      0       1   \n",
      "8     6.052089    12     10      12.0      12.0      0     1      0       1   \n",
      "9     6.244167    12     11      12.0      12.0      0     1      0       1   \n",
      "10    5.416101     9     13      11.0      12.0      0     1      0       1   \n",
      "11    5.991465    12      8      11.0       6.0      0     1      0       1   \n",
      "12    6.033086    11      7      11.0       6.0      0     1      0       1   \n",
      "13    5.379897    11     13      11.0       6.0      0     1      0       1   \n",
      "14    6.795706    16      9       NaN       8.0      1     1      0       1   \n",
      "15    5.703783    14      4      15.0      12.0      0     1      0       1   \n",
      "16    5.846439    12     16      12.0       8.0      0     1      0       1   \n",
      "17    6.489205    14      9       NaN      12.0      0     1      0       1   \n",
      "18    6.354370    10     10       8.0       8.0      0     1      0       1   \n",
      "19    6.475433    12     14       8.0       8.0      0     1      0       1   \n",
      "20    6.850126    18      8      12.0      13.0      0     1      1       1   \n",
      "21    6.419995    18     10       NaN       8.0      0     1      0       1   \n",
      "22    6.587550    15     11       5.0      14.0      0     0      0       1   \n",
      "23    6.403574    12     10      14.0      12.0      0     1      0       1   \n",
      "24    6.541030    12     14      11.0      12.0      0     1      0       1   \n",
      "25    7.244227    18     10      14.0      13.0      0     0      0       1   \n",
      "26    5.703783    12      8       7.0      12.0      0     1      0       1   \n",
      "27    7.495542    18      8      16.0      16.0      0     1      0       1   \n",
      "28    6.023448    12      7      11.0      12.0      0     1      0       1   \n",
      "29    6.448889    14      9       NaN      16.0      0     0      0       1   \n",
      "...        ...   ...    ...       ...       ...    ...   ...    ...     ...   \n",
      "2980  6.437752    16      8       5.0       8.0      1     0      1       0   \n",
      "2981  5.537334    12     12       NaN       NaN      1     0      1       0   \n",
      "2982  6.109248     9     12       NaN       NaN      0     0      1       0   \n",
      "2983  5.926926    12      6       NaN       NaN      1     0      1       0   \n",
      "2984  5.703783    12      8       0.0       7.0      1     1      0       0   \n",
      "2985  5.897154    12      8       8.0      10.0      1     0      1       0   \n",
      "2986  6.620073    18      3       NaN       NaN      1     1      0       0   \n",
      "2987  6.378426    15      7       3.0       8.0      1     1      1       0   \n",
      "2988  5.579730    10     15       0.0       2.0      1     1      1       0   \n",
      "2989  5.703783     9     10       0.0       2.0      1     1      1       0   \n",
      "2990  5.966147     6     21       NaN       NaN      1     0      1       0   \n",
      "2991  6.214608    10     15       NaN      12.0      0     0      1       0   \n",
      "2992  6.109248    12     11       NaN      12.0      0     0      1       0   \n",
      "2993  5.572154    12      9       7.0       7.0      0     0      1       0   \n",
      "2994  6.068426    14      7       5.0      12.0      0     0      1       0   \n",
      "2995  5.257495    10     14       NaN       4.0      1     0      1       0   \n",
      "2996  6.720220    14     14       8.0       8.0      0     0      1       0   \n",
      "2997  6.240276    16      8      16.0      16.0      1     1      1       1   \n",
      "2998  6.270988    13     11       4.0       9.0      1     1      0       1   \n",
      "2999  5.953243    16      4       NaN      11.0      1     0      1       1   \n",
      "3000  6.214608    13      8       6.0       8.0      0     0      1       1   \n",
      "3001  6.568078    15      8      16.0      18.0      0     1      1       1   \n",
      "3002  6.156979    16      5      16.0      18.0      0     1      1       1   \n",
      "3003  6.152733    12      6       NaN       7.0      1     0      1       1   \n",
      "3004  6.023448    13      6       NaN       NaN      1     1      0       1   \n",
      "3005  5.814130    12      7       8.0      12.0      0     0      1       1   \n",
      "3006  6.175867    13     15       NaN       NaN      0     1      1       1   \n",
      "3007  6.214608    12      6      11.0       NaN      0     0      1       1   \n",
      "3008  6.569481    12     13       NaN       NaN      0     0      1       1   \n",
      "3009  6.263398    13      7       NaN       NaN      1     0      1       1   \n",
      "\n",
      "      exper2  const  \n",
      "0        256      1  \n",
      "1         81      1  \n",
      "2        256      1  \n",
      "3        100      1  \n",
      "4        256      1  \n",
      "5         64      1  \n",
      "6         81      1  \n",
      "7         81      1  \n",
      "8        100      1  \n",
      "9        121      1  \n",
      "10       169      1  \n",
      "11        64      1  \n",
      "12        49      1  \n",
      "13       169      1  \n",
      "14        81      1  \n",
      "15        16      1  \n",
      "16       256      1  \n",
      "17        81      1  \n",
      "18       100      1  \n",
      "19       196      1  \n",
      "20        64      1  \n",
      "21       100      1  \n",
      "22       121      1  \n",
      "23       100      1  \n",
      "24       196      1  \n",
      "25       100      1  \n",
      "26        64      1  \n",
      "27        64      1  \n",
      "28        49      1  \n",
      "29        81      1  \n",
      "...      ...    ...  \n",
      "2980      64      1  \n",
      "2981     144      1  \n",
      "2982     144      1  \n",
      "2983      36      1  \n",
      "2984      64      1  \n",
      "2985      64      1  \n",
      "2986       9      1  \n",
      "2987      49      1  \n",
      "2988     225      1  \n",
      "2989     100      1  \n",
      "2990     441      1  \n",
      "2991     225      1  \n",
      "2992     121      1  \n",
      "2993      81      1  \n",
      "2994      49      1  \n",
      "2995     196      1  \n",
      "2996     196      1  \n",
      "2997      64      1  \n",
      "2998     121      1  \n",
      "2999      16      1  \n",
      "3000      64      1  \n",
      "3001      64      1  \n",
      "3002      25      1  \n",
      "3003      36      1  \n",
      "3004      36      1  \n",
      "3005      49      1  \n",
      "3006     225      1  \n",
      "3007      36      1  \n",
      "3008     169      1  \n",
      "3009      49      1  \n",
      "\n",
      "[3010 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "#hw question #3 \n",
    "\n",
    "#load data and set up variables\n",
    "df = pd.read_csv('CARD.csv')\n",
    "df['exper2'] = df['exper'] * df['exper']\n",
    "df['const'] = 1 #note: statsmodel doesn't automatically add a constant. I didn't take off for this\n",
    "print df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.266\n",
      "Model:                            OLS   Adj. R-squared:                  0.264\n",
      "Method:                 Least Squares   F-statistic:                     100.3\n",
      "Date:                Thu, 27 Sep 2018   Prob (F-statistic):          9.71e-143\n",
      "Time:                        14:27:36   Log-Likelihood:                -981.75\n",
      "No. Observations:                2220   AIC:                             1982.\n",
      "Df Residuals:                    2211   BIC:                             2033.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          4.6253      0.080     57.488      0.000       4.467       4.783\n",
      "educ           0.0733      0.004     17.057      0.000       0.065       0.082\n",
      "exper          0.0886      0.008     11.192      0.000       0.073       0.104\n",
      "exper2        -0.0024      0.000     -5.986      0.000      -0.003      -0.002\n",
      "fatheduc      -0.0007      0.003     -0.237      0.812      -0.007       0.005\n",
      "motheduc       0.0078      0.003      2.241      0.025       0.001       0.015\n",
      "black         -0.1614      0.024     -6.684      0.000      -0.209      -0.114\n",
      "smsa           0.1621      0.019      8.749      0.000       0.126       0.198\n",
      "south         -0.1104      0.018     -6.243      0.000      -0.145      -0.076\n",
      "==============================================================================\n",
      "Omnibus:                       61.057   Durbin-Watson:                   1.870\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               75.837\n",
      "Skew:                          -0.333   Prob(JB):                     3.41e-17\n",
      "Kurtosis:                       3.613   Cond. No.                     1.16e+03\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.16e+03. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#part a\n",
    "model = sm.OLS(endog=df['lwage'],\n",
    "               exog=df[['const','educ','exper','exper2','fatheduc','motheduc','black','smsa','south']],\n",
    "               missing='drop')#run a regression of wage against educ without controls\n",
    "\n",
    "results = model.fit()\n",
    "print results.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   educ   R-squared:                       0.483\n",
      "Model:                            OLS   Adj. R-squared:                  0.481\n",
      "Method:                 Least Squares   F-statistic:                     257.9\n",
      "Date:                Thu, 27 Sep 2018   Prob (F-statistic):          8.47e-310\n",
      "Time:                        14:27:36   Log-Likelihood:                -4528.6\n",
      "No. Observations:                2220   AIC:                             9075.\n",
      "Df Residuals:                    2211   BIC:                             9126.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         13.7970      0.270     51.155      0.000      13.268      14.326\n",
      "nearc4         0.2107      0.093      2.276      0.023       0.029       0.392\n",
      "exper         -0.3791      0.038     -9.904      0.000      -0.454      -0.304\n",
      "exper2         0.0025      0.002      1.258      0.208      -0.001       0.006\n",
      "fatheduc       0.1109      0.015      7.622      0.000       0.082       0.139\n",
      "motheduc       0.1307      0.017      7.677      0.000       0.097       0.164\n",
      "black         -0.3557      0.119     -2.986      0.003      -0.589      -0.122\n",
      "smsa           0.2826      0.096      2.941      0.003       0.094       0.471\n",
      "south         -0.0896      0.088     -1.012      0.311      -0.263       0.084\n",
      "==============================================================================\n",
      "Omnibus:                       21.983   Durbin-Watson:                   1.865\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               22.201\n",
      "Skew:                           0.232   Prob(JB):                     1.51e-05\n",
      "Kurtosis:                       2.846   Cond. No.                         792.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "#part c) ii)\n",
    "\n",
    "stage1 = sm.OLS(endog=df['educ'],\n",
    "               exog=df[['const','nearc4','exper','exper2','fatheduc','motheduc','black','smsa','south']],\n",
    "               missing='drop')\n",
    "\n",
    "stage1_results = stage1.fit()\n",
    "print stage1_results.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  lwage   R-squared:                       0.170\n",
      "Model:                            OLS   Adj. R-squared:                  0.167\n",
      "Method:                 Least Squares   F-statistic:                     56.69\n",
      "Date:                Thu, 27 Sep 2018   Prob (F-statistic):           2.99e-84\n",
      "Time:                        14:27:37   Log-Likelihood:                -1118.3\n",
      "No. Observations:                2220   AIC:                             2255.\n",
      "Df Residuals:                    2211   BIC:                             2306.\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           4.1460      1.315      3.153      0.002       1.567       6.725\n",
      "fitted_educ     0.1078      0.095      1.140      0.254      -0.078       0.293\n",
      "exper           0.1016      0.037      2.770      0.006       0.030       0.174\n",
      "exper2         -0.0025      0.000     -5.130      0.000      -0.003      -0.002\n",
      "fatheduc       -0.0046      0.011     -0.414      0.679      -0.026       0.017\n",
      "motheduc        0.0033      0.013      0.261      0.794      -0.022       0.028\n",
      "black          -0.1492      0.042     -3.537      0.000      -0.232      -0.066\n",
      "smsa            0.1500      0.039      3.891      0.000       0.074       0.226\n",
      "south          -0.1062      0.022     -4.826      0.000      -0.149      -0.063\n",
      "==============================================================================\n",
      "Omnibus:                       47.454   Durbin-Watson:                   1.866\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):               56.700\n",
      "Skew:                          -0.292   Prob(JB):                     4.87e-13\n",
      "Kurtosis:                       3.521   Cond. No.                     1.78e+04\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.78e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "#part c) iii)\n",
    "\n",
    "df['fitted_educ'] = stage1_results.fittedvalues\n",
    "\n",
    "stage2 = sm.OLS(endog=df['lwage'],\n",
    "               exog=df[['const','fitted_educ','exper','exper2','fatheduc','motheduc','black','smsa','south']],\n",
    "               missing='drop')\n",
    "\n",
    "stage2_results = stage2.fit()\n",
    "print stage2_results.summary() #note, the standard errors are not correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7978940313971696\n",
      "0.38199401568343355\n",
      "0.00450937114421252\n"
     ]
    }
   ],
   "source": [
    "#part c) iv)\n",
    "\n",
    "######### sigma_d #########\n",
    "\n",
    "sigma_d = np.sqrt(stage1_results.fittedvalues.var())\n",
    "print sigma_d\n",
    "\n",
    "######### sigma_et a#########\n",
    "\n",
    "#need to calculate 'correct' resid using formula in textbook\n",
    "\n",
    "y= np.array(df['lwage']) #cast to np, to do matrix multiplication\n",
    "x = np.array(df[['const','educ','exper','exper2','fatheduc','motheduc','black','smsa','south']])\n",
    "\n",
    "stage2_resid =  y - np.matmul(x,stage2_results.params)\n",
    "stage2_resid = stage2_resid[~np.isnan(stage2_resid)] #missing values\n",
    "\n",
    "#we're done!\n",
    "sigma_eta = np.sqrt(stage2_resid.var()) \n",
    "print sigma_eta\n",
    "\n",
    "########## actual formula #########\n",
    "sqrt_n = np.sqrt(len(stage2_resid))\n",
    "print sigma_eta/( sqrt_n * sigma_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
